task	description
ArchiStandard	The ARCHI tasks are a battery of localizers comprising a wide range of psychological domains. This task, described in [Pinel et al., 2007](https://doi.org/10.1186/1471-2202-8-91) probes basic functions, such as button presses with the left or right hand, viewing horizontal and vertical checkerboards, reading and listening to short sentences, and mental computations (subtractions). Visual stimuli were displayed in four 250-ms epochs, separated by 100ms intervals (i.e., 1.3s in total). Auditory  stimuli were generated from a recorded male voice (i.e., a total of 1.6s for motor instructions, 1.2-1.7s for sentences, and 1.2-1.3s for subtraction). The auditory or visual stimuli were shown to the participants for passive viewing or button response in event related paradigms. Informal inquiries undertaken after the MRI session confirmed that the experimental tasks were understood and followed correctly.
ArchiSpatial	The ARCHI tasks are a battery of localizers comprising a wide range of psychological domains. This task includes the performance of (1) ocular saccade, (2) grasping and (3) orientation judgments on objects (the two different tasks were actually made on the same visual stimuli in order to characterize grasping-specific activity), (4) judging whether a hand photograph was the left or right hand or (5) was displaying the front or back. The same input stimuli were presented twice in order to characterize specific reponse to hand side judgment.
ArchiSocial	The ARCHI tasks are a battery of localizers comprising a wide range of psychological domains. This task relies on (1) the interpretation of short stories involving false beliefs or not, (2) observation of moving objects with or without a putative intention, and (3) listening to speech and non-speech sounds.
ArchiEmotional	The ARCHI tasks are a battery of localizers comprising a wide range of psychological domains. This task includes (1) facial judgments of gender, and (2) trustworthiness plus expression based on complete portraits or photos of eyes’ expressions.
HcpEmotion	The main purpose of HCP Emotion task was to capture neural activity arising from fear- or angry-response processes. To elicit stronger effects, affective facial expressions were used as visual stimuli due to their importance in adaptive social behavior [Hariri et al., 2002](https://doi.org/10.1006/nimg.2002.1179). The paradigm was thus composed by two categories of blocks: (1) the face block, and (2) the shape block. All blocks consisted of a series of events, in which images with faces or shapes were displayed, respectively. There were always three faces/shapes per image; one face/shape was shown at the top and two faces/shapes were shown at the bottom. The participants were then asked to decide which face/shape at the bottom, i.e. left or right face/shape, matched the one displayed at the top, by pressing respectively the index or middle finger’s button of the response box. The task was formed by twelve blocks per run, i.e. six face blocks and six shape blocks. The two block categories were alternately presented for each run. All blocks contained six trials and they were always initiated by a cue of three seconds. In turn, the trials included a visual-stimulus period of two seconds and a fixation-cross period of one second; the total duration of the trial was thus three seconds.
HcpGambling	This task was adapted from the Incentive processing task-fMRI paradigm of the HCP and its aim was to localize brain structures that take part to the reward system, namely the basal ganglia complex. The paradigm included eight blocks and each block was composed by eight events. For every event, the participants were asked to play a game. The goal was to guess whether the next number to be displayed, which ranged from one to nine, would be more or less than five while a question mark was shown on the screen. The answer was given by pressing the index or middle finger’s button of the response box, respectively. Feedback on the correct number was provided afterwards. There was an equal amount of blocks in which the participants experienced either reward or loss, for most of the events. Concretely, six out of the eight events within a block pertained to one of these two outcomes; the remaining events corresponded to the antagonist or a neutral outcome, i.e. when the correct number was five. The task was constituted by eight blocks per run, in which each half related to reward and loss experience, respectively. The order of the two block categories were pseudorandomized during a single run, but fixed for all participants. A fixation-cross period of fifteen seconds was displayed between blocks. All blocks contained eight trials. The trials included a question-mark visual stimulus lasting up to 1.5 seconds, a feedback period of one second and a fixation-cross period of one second, as well; the total duration of the trial was then 3.5 seconds, approximately.
HcpMotor	HCP Motor task was designed with the intent of extracting maps on gross motor topography, in particular motor skills associated with movements of the foot, hand and tongue. There were thus five categories of blocks with respect to motor tasks involving (1) the left foot, (2) the right foot, (3) the left hand, (4) the right hand, and (5) the tongue, respectively. The blocks always started with visual cues referring to which part of the body should be moved. The cues were then followed by a set of events, which were in turn indicated by flashing arrows on the screen. The events pertained to the corresponding movements performed by the participants. The task was formed by five blocks per category, with a total of twenty blocks per run. The order of the block categories were pseudo-randomized during each run, but fixed for all participants. A fixation-dot period of fifteen seconds was inserted between some blocks. All blocks contained ten trials. Every trial included a cue of one second and a period of performance of twelve seconds4; the total duration of the trial was then thirteen seconds.
HcpLanguage	HCP Language task was used as a localizer of brain regions involved in semantic processing, with special focus on the anterior temporal lobe (ATL) [Binder et al., 2011](https://doi.org/10.1016/j.neuroimage.2010.09.048). The paradigm comprised two categories of blocks: (1) story blocks, and (2) math blocks. The math block served as a control task in this context, since it was likely to adress other brain regions during the attentional demands. Both type of blocks exhibited auditory stimuli in short epochs, which in turn finished with a final question followed by two possible answers. During story blocks, participants were presented with stories, whose question targeted their respective topics. Conversely, math blocks showed arithmetic problems for which the correct solution must be selected. The answer was provided after the two possible options were displayed, through pressing the corresponding button of the response box, i.e. the button for the index or middle finger of the response box for the first or second option, respectively. The difficulty levels of the problems, presented for both categories, were adjusted throughout the experiment, in order to keep the participants engaged in the task and, thus, assure accurate performances. The task was composed by eleven blocks per run. For the first run, six story blocks and five math blocks were interleaved, respectively. The reverse amount and order of blocks were used during the second run. The number of trials per block varied between one and four. Nevertheless, it was assured that both block categories matched their length of presentation at every run. There was a cue of two seconds in the beginning of each block, indicating its category. The duration of the trials within a block varied between ten and thirty seconds. Finally, the presentation of the auditory stimuli was always accompanied by the display of a fixation cross on the screen throughout the entire run.
HcpRelational	HCP Relational task employed a relational matching-to-sample paradigm, featuring a second-order comparison of relations between two pairs of objects. It served primarily as a localizer of the rostrolateral prefrontal cortex, since relational matching mechanisms were shown to elicit activation on this region [Smith et al., 2007](https://doi.org/10.1016/j.neuroimage.2007.04.032). Similarly to some previous tasks, two categories of blocks described the paradigm: (1) the relational-processing block, and (2) the control-matching block. All blocks were constituted by a set of events. In the relational-processing block, visual stimuli consisted of images representing two pairs of objects, in which one pair was placed at the top and the other one at the bottom of the image, respectively. Objects within a pair may differ in two dimensions: shape and texture. The participants had to identify whether the pair of objects from the top differed in a specific dimension and, subsequently, they were asked to determine whether the pair from the bottom changed along the same dimension. For the control block, one pair of objects was displayed at the top of the image and a single object at the bottom of the same image. In addition, a cue was shown in the middle of that image referring to one of the two possible dimensions. The participants had thus to indicate whether the object from the bottom was matching either of the two objects from the top, according to the dimension specified as a cue. If there was a match they had to press with the index finger on the corresponding button of the button box; otherwise, they had to press with the middle finger on the corresponding one. This task was formed by twelve blocks per run. Two groups of six blocks referred to the two block categories, respectively. Block categories were, in turn, interleaved for display within a run. A fixation-cross period of sixteen seconds was inserted between some blocks. All blocks contained six trials and they were always initiated by a cue of two seconds. The trials were described by a visual-stimulus plus response period followed by a fixation-cross period, lasting up to ten seconds. The duration of the former differed in agreement with the type of block, i.e. it lasted nine seconds and 7.6 seconds during the relational-processing block and control-matching block, respectively.
HcpSocial	HCP Social task intended to provide evidence for task-specific activation in brain structures presumably implicated in social cognition. The paradigm included two categories of blocks, in which movies were presented during short epochs. The movies consisted in triangle-shape clip art, moving in a predetermined fashion. Putative social interactions could be drawn from movements referring to the block category on the effect-of-interest. In contrast, objects appeared to be randomly moving the other category, i.e. the control-effect block. Participants were to decide whether the movements of the objects appeared to represent a social interaction (by pressing with the index finger in the corresponding button of the response box) or not (by pressing with the ring finger in the corresponding button of the response box; in case of uncertainty, they had to press with the middle finger. The task was constituted by ten blocks per run. Each half of the blocks corresponded to one of the aforementioned block categories, whose order was pseudo-randomized for every run, but fixed for all participants. There was only one trial present per block. It consisted of a twenty-second period of video-clip presentation plus three seconds maximum of a response period, indicated by a momentary instruction on the screen. Thus, the total duration of a block was approximately twenty three seconds. A fixation-cross period of fifteen seconds was always displayed between blocks. 
HcpWm	HCP Working Memory task was adapted from the classical n-back task to serve as functional localizer for evaluation of working-memory (WM) capacity and related processes. The paradigm integrated two categories of blocks: (1) the “0-back” WM-task block, and (2) the “2-back” WM-task block. They were both equally presented within a run. A cue was always displayed at the beginning of each block, indicating its task-related type. Blocks were formed by set of events, during which pictures of faces, places, tools or body parts were shown on the screen. One block was always dedicated to one specific category of pictures and the four categories were always presented at every run. At each event, the participant were to decide whether the image matched with the reference or not, by pressing respectively on the index or middle finger’s button of the response box. The task was constituted by sixteen blocks per run, splitted into two block categories. Besides, there were four pairs of blocks per category, referring respectively to the four classes of pictures mentioned above. The order of the blocks, regardless their category and corresponding class of pictures, was pseudo-randomized for every run, but fixed for all participants. A fixation-cross period of fifteen seconds was introduced between some blocks. All blocks contained ten trials and they were always initiated by a cue of 2.5 seconds. Trials included in turn the presentation of a picture for two seconds and a very short fixation-cross period for half of a second; the total duration of one trial was thus 2.5 seconds.
RSVPLanguage	The Rapid-Serial-Visual-Presentation (RSVP) Language task was adapted from the study undertaken by [Humphries et al., 2006](10.1162/jocn.2006.18.4.665) on syntactic and semantic processing during auditory sentence comprehension. Specifically, the task herein described targeted the same syntactic and semantic modules, but in the context of reading. It thus allowed for capturing further associations with regard to e.g. visual (pseudo) word recognition and sublexical route, among other aspects related to active reading. The paradigm consisted in a block-design presentation strategy of the stimuli. One block was defined as an epoch within a trial and epochs corresponded in turn to experimental conditions. Such conditions stood for the consecutive visual presentation of ten constituents composed by letters. All linguistic content elicited from the conditions except “consonant strings”, such as grammar rules, lexicon and phonemes, were part of the french language. In order to ensure continuous engagement during task performance, participants were asked, straight afterwards the visualization of every sentence, to ascertain whether the current constituent displayed on the screen, aka “the probe”, was part of the previous sentence or not. The corresponding answer was provided immediately after the probe, by pressing the button in the left hand if “yes” or the one in the right hand if “no”. Data were collected in six runs during one single session. Every run was composed by sixty trials, in which subsets of ten trials were dedicated to each condition, respectively. The order of the trials was pseudo-randomized within and between runs, such that there were no repeated trials during a full session. Moreover, a different pseudo-randomized order for the presentation of the trials was always employed across participants. One trial comprised several experimental manipulations, other than a block integrating one specific condition. It was sequentially formed by a period of fixation-cross display (two seconds), another short period of a blank screen (0.5 seconds), a block containing the linguistic stimuli (0.4 seconds × 10 = 4 seconds), a jittered blank screen (varying from one to 1.5 seconds), a period of a second fixation-cross display (0.5 seconds), a period for the probe display (0.5 seconds), and, finally, a response period (varying up to two seconds). The total duration of one single trial was thus ten seconds. Three extra seconds of blank screen were added at the beginning of every run, i.e. before the presentation of the first trial. Two opposite phase-encoding directions were respectively applied during acquisition of each half of the total amount of runs.
MTTWE	Participants were to judge the ordinality of real historical events in time and space by mentally project oneself, i.e. through egocentric mapping. In contrast, the present task was intended to assess the neural correlates underlying both mental time and space judgment involved in allocentric mapping implemented in narratives. To this end, and in order to remove confounds associated with prior subject-specific mental representations linked to the historical events, fictional scenarios were created with fabricated stories and characters.  The stimuli of each task referred to a different island plotting different stories and characters. There were two stories per island and they were created based on a two-dimensional mesh of nodes. Each node corresponded to a specific action. The stories of each island evolved both in time and in one single cardinal direction. The cardinal directions, cued in the task, differed between sessions. Thus, space judgment was performed according to the cardinal directions West-East. In addition, the stories of each island evolved spatially in opposite ways. For instance, the two stories plotted in the West-East island evolved across time from west to east and east to west, respectively.
MTTNS	Participants were to judge the ordinality of real historical events in time and space by mentally project oneself, i.e. through egocentric mapping. In contrast, the present task was intended to assess the neural correlates underlying both mental time and space judgment involved in allocentric mapping implemented in narratives. To this end, and in order to remove confounds associated with prior subject-specific mental representations linked to the historical events, fictional scenarios were created with fabricated stories and characters. The stimuli of each task referred to a different island plotting different stories and characters. There were two stories per island and they were created based on a two-dimensional mesh of nodes. Each node corresponded to a specific action. The stories of each island evolved both in time and in one single cardinal direction. The cardinal directions, cued in the task, differed between sessions. Thus, space judgment was performed according to the cardinal directions South-North. In addition, the stories of each island evolved spatially in opposite ways. For instance, the two stories plotted in the South-North island evolved across time from north to south and south to north, respectively.
PreferenceFood	The Preference task battery was adapted from the Pleasantness Rating task described in [Lebreton et al., 2015](https://doi.org/10.1038/nn.4064), in order to capture the neural correlates underlying the decision-making for potentially rewarding outcomes (aka “positive-incentive value”) as well as the level of confidence of such type of action. The whole task battery is composed of four tasks, each of them pertaining to the presentation of items of a certain kind. Therefore, Food task was dedicated to “food items”. All tasks were organized as a block-design experiment with one condition per trial. Every trial started with a fixation cross, whose duration was jittered between 0.5 seconds and 4.5 seconds, after which a picture of an item was displayed on the screen together with a rating scale and a cursor. Participants were to indicate how pleasant the presented stimulus was, by sliding the cursor along the scale. Index and ring finger’s of the response box were to move respectively with low and high speed to the left whereas the middle and little fingers were to move respectively with low and high speed to the right; thumb’s button was used to validate the answer. The scale ranged between 1 and 100. The value 1 corresponded to the choices “unpleasant” or “indifferent”; the middle of the scale corresponded to the choice “pleasant”; and the value 100 corresponded to the choice “very pleasant”. Therefore, the ratings related only to the estimation of the positive-incentive value of the items displayed. 
PreferencePaintings	The Preference task battery was adapted from the Pleasantness Rating task described in [Lebreton et al., 2015](https://doi.org/10.1038/nn.4064), in order to capture the neural correlates underlying the decision-making for potentially rewarding outcomes (aka “positive-incentive value”) as well as the level of confidence of such type of action. The whole task battery is composed of four tasks, each of them pertaining to the presentation of items of a certain kind. Therefore, Painting task was dedicated to “paintings”. All tasks were organized as a block-design experiment with one condition per trial. Every trial started with a fixation cross, whose duration was jittered between 0.5 seconds and 4.5 seconds, after which a picture of an item was displayed on the screen together with a rating scale and a cursor. Participants were to indicate how pleasant the presented stimulus was, by sliding the cursor along the scale. Index and ring finger’s of the response box were to move respectively with low and high speed to the left whereas the middle and little fingers were to move respectively with low and high speed to the right; thumb’s button was used to validate the answer. The scale ranged between 1 and 100. The value 1 corresponded to the choices “unpleasant” or “indifferent”; the middle of the scale corresponded to the choice “pleasant”; and the value 100 corresponded to the choice “very pleasant”. Therefore, the ratings related only to the estimation of the positive-incentive value of the items displayed. 
PreferenceFaces	The Preference task battery was adapted from the Pleasantness Rating task described in [Lebreton et al., 2015](https://doi.org/10.1038/nn.4064), in order to capture the neural correlates underlying the decision-making for potentially rewarding outcomes (aka “positive-incentive value”) as well as the level of confidence of such type of action. The whole task battery is composed of four tasks, each of them pertaining to the presentation of items of a certain kind. Therefore, Face task was dedicated to “human faces”. All tasks were organized as a block-design experiment with one condition per trial. Every trial started with a fixation cross, whose duration was jittered between 0.5 seconds and 4.5 seconds, after which a picture of an item was displayed on the screen together with a rating scale and a cursor. Participants were to indicate how pleasant the presented stimulus was, by sliding the cursor along the scale. Index and ring finger’s of the response box were to move respectively with low and high speed to the left whereas the middle and little fingers were to move respectively with low and high speed to the right; thumb’s button was used to validate the answer. The scale ranged between 1 and 100. The value 1 corresponded to the choices “unpleasant” or “indifferent”; the middle of the scale corresponded to the choice “pleasant”; and the value 100 corresponded to the choice “very pleasant”. Therefore, the ratings related only to the estimation of the positive-incentive value of the items displayed. 
PreferenceHouses	The Preference task battery was adapted from the Pleasantness Rating task described in [Lebreton et al., 2015](https://doi.org/10.1038/nn.4064), in order to capture the neural correlates underlying the decision-making for potentially rewarding outcomes (aka “positive-incentive value”) as well as the level of confidence of such type of action. The whole task battery is composed of four tasks, each of them pertaining to the presentation of items of a certain kind. Therefore, House task was dedicated to “houses”. All tasks were organized as a block-design experiment with one condition per trial. Every trial started with a fixation cross, whose duration was jittered between 0.5 seconds and 4.5 seconds, after which a picture of an item was displayed on the screen together with a rating scale and a cursor. Participants were to indicate how pleasant the presented stimulus was, by sliding the cursor along the scale. Index and ring finger’s of the response box were to move respectively with low and high speed to the left whereas the middle and little fingers were to move respectively with low and high speed to the right; thumb’s button was used to validate the answer. The scale ranged between 1 and 100. The value 1 corresponded to the choices “unpleasant” or “indifferent”; the middle of the scale corresponded to the choice “pleasant”; and the value 100 corresponded to the choice “very pleasant”. Therefore, the ratings related only to the estimation of the positive-incentive value of the items displayed. 
TheoryOfMind	This battery of tasks was adapted from the original task-fMRI localizers of Saxe Lab ( https://saxelab.mit.edu/localizers), intended to identify functional regions-of-interest in the Theory-of-Mind network and Pain Matrix regions. The Theory-of-Mind Localizer (TOM localizer) was intended to identify brain regions involved in theory-of-mind and social cognition, by contrasting activation during two distinct story conditions: belief judgments, reading a false-belief story that portrayed characters with false beliefs about their own reality; and fact judgments, reading a story about a false photograph, map or sign [Dodell-Feder et al., 2011](https://doi.org/10.1016/j.neuroimage.2010.12.040). The task was organized as a block-design experiment with one condition per trial. Every trial started with a fixation cross of twelve seconds, followed by the main condition that comprised a reading period of eighteen seconds and a response period of six seconds. During this response period, participants were to judge whether a statement about the story previously displayed is true or false by pressing respectively with the index or middle finger in the corresponding button of the response box. The total duration of the trial amounted to thirty six seconds. There were ten trials in a run, followed by an extraperiod of fixation cross for twelve seconds at the end of the run. Two runs were dedicated to this task in one single session.
EmotionalPain	The Theory-of-Mind and Pain-Matrix Narrative Localizer (Emotional Pain localizer) was intended to identify brain regions involved in theory-of-mind and Pain Matrix areas, by contrasting activation during two distinct story conditions: reading a story that portrayed characters suffering from emotional pain and physical pain [Jacoby et al., 2016]( https://doi.org/10.1016/j.neuroimage.2015.11.02). The experimental design of this task is identical to the one employed for the TOM localizer, except that the reading period lasted twelve seconds instead of eighteen seconds. During the response period, the participant had to the judge the amount of pain experienced by the character(s) portrayed in the previous story. For no pain, they had to press with their thumb on the corresponding button of the response box; for mild pain, they had to press with their index finger; for moderate pain, they had to press with the middle finger; and for a strong pain, they had to press with the ring finger.
PainMovie	The Theory-of-Mind and Pain Matrix Movie Localizer (Pain Movie localizer) consisted in the display of “Partly Cloud”, a 6 minutes movie from Disney Pixar, in order to study the responses implicated in theory-of-mind and Pain Matrix brain regions [Richardson et al., 2018](https://doi.org/10.1038/s41467-018-03399-2). Two main conditions were thus hand-coded in the movie, according to [15], as follows: mental movie, in which characters were “mentalizing”; and physical pain movie, in which characters were experiencing physical pain. Such conditions were intended to evoke brain responses from theory-of-mind and pain-matrix networks, respectively. All moments in the movie not focused on the direct interaction of the main characters were considered as a baseline period.
VSTM	This battery of tasks was adapted from the control experiment described in [Knops et al., 2014](https://doi.org/10.1523/JNEUROSCI.2758-13.2014). In the Visual Short-Term Memory (VSTM) task, participants were presented with a certain number of bars, varying from one to six. Every trial started with the presentation of a black fixation dot in the center of the screen for 0.5 seconds. While still on the screen, the black fixation dot was then displayed together with a certain number of tilted bars –variable between trials from one to six for 0.15 seconds. Afterwards, a white fixation dot was shown for 1 second. It was next replaced by the presentation of the test stimulus for 1.7 seconds, displaying identical number of tilted bars in identical positions together with a green fixation dot. The participants were to remember the orientation of the bars from the previous sample and answer with one of the two possible button presses, i.e. respectively with the index or middle finger, depending on whether one of the bars in the current display had changed orientation by 90◦ or not, which was the case in half of the trials. The test display was replaced by another black fixation dot for a fixed duration of 3.8 seconds. Thus, the trial was 7.15 seconds long. There were seventy two trials in a run and four runs in one single session. Pairs of runs were launched consecutively. To avoid selection bias in the sequence of stimuli, the order of the trials was shuffled according to numerosity and change of orientation within runs and across participants. Both the response period and the period of the fixation dot at the end of each trial were made constant.
Enumeration	This battery of tasks was adapted from the control experiment described in [Knops et al., 2014](https://doi.org/10.1523/JNEUROSCI.2758-13.2014). The stimuli consisted of sets of tilted dark-gray bars displayed on a light-gray background. In the Enumeration task, participants were presented with a certain number of bars, varying from one to eight. Every trial started with the presentation of a black fixation dot in the center of the screen for 0.5 seconds. While still on the screen, the black fixation dot was then displayed together with a certain number of tilted bars for 0.15 seconds. It was followed by a response period of 1.7s, in which only a green fixation dot was being displayed on the screen. The participants were to remember the number of the bars that were shown right before and answer accordingly, by pressing the corresponding button: once with the thumb’s button for one bar; once with the index finger’s button for two bars; once with the middle finger’s button for three bars; once with the ring finger’s button for four bars; twice with the thumb’s button for five bars; twice with the index finger’s button for six bars; twice with the middle finger’s button for seven bars; twice with the ring finger’s button for eight bars. Afterwards, another black fixation dot was displayed for a fixed duration of 7.8 seconds. The trial length was thus 9.95 seconds. There were ninety six trials in a run and two (consecutive) runs in one single session. To avoid selection bias in the sequence of stimuli, the order of the trials was shuffled according to numerosity within runs and across participants. Both the response period and the period of the fixation dot at the end of each trial were made constant.
Self	The Self task was adapted from [Genom et al., 2014](https://doi.org/10.1016/j.cortex.2013.06.009), originally developed to investigate the Self-Reference Effect in older adults. This effect pertains to the encoding mechanism of information referring to the self, characterized as a memory-advantaged process. Consequently, memory-retrieval performance is also better for information encoded in reference to the self than to other people, objects or concepts. The present task was thus composed of two phases, each of them relying on encoding and recognition procedures. The encoding phase was intended to map brain regions related to the encoding of items in reference to the self, whereas the recognition one was conceived to isolate the memory network specifically involved in the retrieval of those items. The phases were interspersed, so that the recognition phase was always related to the encoding phase presented immediately before.
Bang	The Bang task was adapted from the study [Campbell et al., 2015](https://doi.org/10.1016/j.neurobiolaging.2015.07.028), dedicated to investigate aging effects on neural responsiveness during naturalistic viewing. The task relies on watching –viewing and listening– of an edited version of the episode “Bang! You’re Dead” from the TV series “Alfred Hitchcock Presents”. The original black-and-white, 25-minute episode was condensed to seven minutes and fifty five seconds while preserving its narrative. The plot of the final movie includes scenes with characters talking to each other as well as scenes with no verbal communication. This task was performed during a single run in one unique session. Participants were never informed of the title of the movie before the end of the session.
Clips	The Clips battery stands for an adaptation of [Nishimoto et al., 2011](https://doi.org/10.1016/j.cub.2011.08.031), in which participants were to visualize naturalistic scenes edited as video clips of ten and a half minutes each. Each run was always dedicated to the data collection of one video clip at a time. As in the original study, runs were grouped in two tasks pertaining to the acquisition of training data and test data, respectively. Scenes from training-clips (ClipsTrn) task were shown only once. Contrariwise, scenes from the test-clips (ClipsVal) task were composed of approximately one-minute-long excerpts extracted from the clips presented during training. Excerpts were concatenated to construct the sequence of every ClipsVal run; each sequence was predetermined by randomly permuting many excerpts that were repeated ten times each across all runs. The same randomized sequences, employed across ClipsVal runs, were used to collect data from all participants.
Retinotopy-Wedge	The Retinotopy tasks refer to the classic retinotopic paradigms –the Wedge and the Ring tasks– consisting of two kinds of visual stimuli as part of the Wedge task: a slowly rotating clockwise or counterclockwise and semicircular checkerboard stimulus. The phase of the periodic response at the rotation or dilation/contraction frequency measured at each voxel relates to the measurement of the perimetric parameters concerning polar angle and eccentricity, respectively [Sereno et al., 1995] (https://doi.org/10.1126/science.7754376).
Retinotopy-Ring	The Retinotopy tasks refer to the classic retinotopic paradigms –the Wedge and the Ring tasks– consisting of two kinds of visual stimuli as part of the Ring task: a thick, dilating or contracting ring. The phase of the periodic response at the rotation or dilation/contraction frequency measured at each voxel relates to the measurement of the perimetric parameters concerning polar angle and eccentricity, respectively [Sereno et al., 1995] (https://doi.org/10.1126/science.7754376). 
Raiders	The Raiders task was adapted from [Haxby et al., 2011](http://doi.org/10.1016/j.neuron.2011.08.026), in which the full-length action movie Raiders of the Lost Ark was presented to the participants. The main goal of the original study was the estimation of the hyperalignment parameters that transform voxel space of functional data into feature space of brain responses, linked to the visual characteristics of the movie displayed. Similarly, herein, the movie was shown to the IBC participants in contiguous runs determined according to the chapters of the movie defined in the DVD. This task was completed in two sessions. In order to use the acquired fMRI data in train-test split and cross-validation experiments, we performed three extra-runs at the end of the second session in which the three first chapters of the movie were repeated.
Lec2	Originally described in [Perrone-Bertolotti et al., 2012](https://doi.org/10.1523/JNEUROSCI.2982-12.2012), this task focuses on silent reading. During the task, participants were presented with two intermixed stories, shown word by word at a rapid rate. One of the stories was written in black (on a gray screen) and the other in white. Consecutive words with the same color formed a meaningful and simple short story in French. Participants were instructed to read the black story to report it at the end of the block, while ignoring the white one. Each block comprised 400 words, with 200 black words (attend condition) and 200 white words (ignore condition) for the two stories. The time sequence of colors within the 400 words series was randomized, so that participants could not predict whether the subsequent word was to be attended or not; however, the randomization was constrained to forbid series of more than three consecutive words with the same color.
Audi	Described in [Perrone-Bertolotti et al., 2012](https://doi.org/10.1523/JNEUROSCI.2982-12.2012). Participants listened to sounds of several categories with the instruction that three of them would be presented again at the end of the task, together with three novel sounds and that they should be able to detect previously played items. There were three speech and speech-like categories, including sentences told by a computerized voice in a language familiar to the participant (French) or unfamiliar (Suomi), and reversed speech, originally in French (the same sentences as the “French” category, played backwards). These categories were compared with nonspeech-like human sounds (coughing and yawning), music, environmental sounds, and animal sounds.
Visu	This task, described in [Vidal et al., 2010](https://doi.org/10.3389/fnhum.2010.00195), is a visual odd-ball paradigm, in which participants were instructed to press a button (index finger) every time they see a fruit. Images of the target category and other non-target categories were rapidly presented in a pre-randomized order. Stimuli were presented for a duration of 200ms every 1000–1200ms in series of 5 pictures interleaved by 3-second pause periods during which patients could freely blink. Each non-target category was presented 50 times during the experiment, and data was acquired in two separated runs.
Lec1	This task, described in [Saignavong et al., 2017](https://doi.org/10.1142/S0129065717500010), was originally used to test whether brain activity can be deteted in single trials with intracerebral EEG-fMRI recordings. During the task, participants were presented with three vertically-arranged lines, indicated by the presence of two “+” symbols at both sides, and empty space between them. For each row, a different type of verbal stimulli was presented, and the participant was instructed to make a decission depending on the type of stimuli. The top row presented words, and the decision was an animacy decision (“Is it a living entity?”). The middle row presented pseudowords, and the decision was whether the pseudoword had one or two syllabes. Finally, the bottom row presented consonant strings, and participants were instructed to answer if the string was all-uppercase or all-lowercase. First option was selected by pressing with the index finger on the response box whereas second option was given with the middle finger.
MVEB	This task, described in [Hamamé et al., 2012](https://doi.org/10.1016/j.neuroimage.2011.07.087), aims to assess verbal working memory (the name stands for “verbal working memory task”). In this case, the participant is presented with a string of 6 characters, from where two, four or six of them can be letters (the rest are “#” symbols). After the string disappears, a single letter appears in screen. The participant had then to indicate if this single letter was part of the previously presented string. This was indicated by the participant with a 5-button response box, with one button for “yes” (index finger) and another for “no” (middle finger). The cognitive load was manipulated with the number of letters, and one condition was included where all the letters of the initial string would be the same one.
MVIS	This task, described in [Hamamé et al., 2012](https://doi.org/10.1016/j.neuroimage.2011.07.087), and whose name stands for “visuo-spatial working memory” task, consists on a series of events in which the participant will be presented with a 4x4 grid in which two, four or six dots will appear at different positions, after that, the grid would become empty and finally a single dot would appear on it. The participant had then to indicate if this single dot was in the same position than any of the previously presented ones. This was indicated by the participant with a 5-button response box, with one button for “yes” (index finger) and another for “no” (middle finger). The cognitive load was manipulated with the number of dots, and one condition was included where one of the dots would be highlighted, signifying that was the only position to retain.
Moto	This task is a basic motor localizer for several body parts. The participants are presented with three small gray squares over a black background image. At the beginning of each block, a text prompt will appear on screen to indicate the body part that will be moved next. Afterwards, the left and right squares will turn white to indicate movement of the corresponding part. For example, for the hands condition, the participant is required to perform a small movement of the left hand when the left square turns white, and likewise for the right hand. Ten movements were prompted for each block, five for the right body part and five for the left, consecutively for each direction and always in the same order.
MCSE	This task described in [Ossandón et al., 2012](https://doi.org/10.1523/JNEUROSCI.6048-11.2012) was originally used to study whether visual search processes of a salient target can be thought as a purely bottom-up process, or if it requires action from top-down attentional processess. The task consisted in the presentation of an array of 35 “L” letters, rotated at different angles, together with a target “T” letter (total 36 stimuli in each trial). Subjects were instructed to search for the target and indicate whether it was on the left or right side of the grid, by pressing respectively with the index or middle finger on a 5-button response box. There were two conditions: high-salience (the target is gray while the other stimuli is black) and low-salience (all stimuli are gray).
Audio (Realistic Sounds)	This task, originally described in [Santoro et al., 2017](https://doi.org/10.1073/pnas.1617622114), is an auditory localizer. During each run, the participants were presented with sounds from different categories, and were instructed to press a button with the index finger whenever two consecutive sounds were identical. From a group of 288 sounds, divided into 6 different categories, 4 sets were created. Each set contained 72 sounds of each of the categories, and each one was present only in one of the sets. Furthermore, each set was pre-randomized in 3 different orders, and the same sequences were used for all participants. On top of the 72 sounds, each run also included 5 silences and 5 repeated sounds from the original 72. In total, each run consisted of 82 trials of 2 seconds each. It is important to note that the data for this task was acquired using an interrupted acquisition sequence, to minimize the effect that scanner noise can have in the auditory processing targeted by the experiment. To this end, the inter-stimulus interval was programmed in a sequence of 4, 4, and 6 seconds, meaning that the interval between stimuli would be 4s for the first trial, 4s for the second, 6s for the third, and then the sequence repeats until the end of the run. The variability of the ISI and the silence trials avoided stimulus’ presentation to be predictable in time.
Attention	This task is a version of the classical flanker task [Eriksen, Eriksen, 1974](https://doi.org/10.3758/BF03203267), where the participant has to judge the direction the target flanker (an arrow) is pointing to (left/right). The target flanker is surrounded by other 4 flankers that can be congruent or incongruent with the target one, thus capturing selective attention and inhibitory processes. Two different buttons (index and middle fingers’ button, respectively) were assigned to left/right responses, and the participant had to indicate the direction of the central arrow from an horizontal group of 5 arrows. In each trial, one or two positional cues were presented above and below the center of the screen. When one cue was given, the flankers would appear centered around it, whereas when two cues where presented, the flankers would appear centered around one of them. The four flankers surrounding the target would always point to the same direction, and can be congruent or incongruent with the direction the target flanker is facing.
StopSignal	This task was originally used to localize activation relative to inhibition of a prominent motor response [Bissett, Logan, 2011](https://doi.org/10.1037/a0021800). Four different polygonal shapes composed the set from which one of them was presented in each trial. Two of them were assigned to the button corresponding to the index finger, and two of them to the button corresponding to the middle finger. The participants were instructed to press the correct button as fast as possible, except if a red-colored star appeared on top of the target stimulus. There were 12 practice trials followed by 123 test trials divided in 3 blocks of 41 trials each, with a resting period of 9 seconds in between blocks. During practice, feedback was provided to indicate correct and incorrect responses, as well as to indicate if the responses were too slow. No stop trials (red star) were present during practice, although the instructions pertaining the red star were presented before practice. This was to build a predominant motor response in order to better capture inhibitory processes.
TwoByTwo	This protocol aimed to study the responses to task-switching and cue-switching in every trial, with the aim to asses the activity elicted by switching either or both task and cue, and how switching one affects the response to the other. It consisted of presenting colored single-digit numbers from 1 to 9, preceded by a cue string indicating which task must be performed. For each trail, the task could either be to judge if the number is greater or less than 5; or to judge whether the digit shown is colored in blue or orange. For each of the two tasks, two different strings could be used as cue: for the first, the cue could display either `Magnitude' or `High/Low', both strings indicating the participant must judge the quantity; for the second task, the subject could read either `Color' or `Orange/Blue' as cues, both strings indicating the task is to judge the color. Two different buttons (index/middle finger) were assigned to the orange/high and blue/low options, respectively. The task is composed by 16 practice trials, followed by 240 trials divided in 3 blocks of 80 trials each. The order of cue and task switching was randomized.
Discount	In this decision-making task, the participant has to decide whether to take a figurative amount of 20 dollars today or a bigger amount in a set number of days. The task is composed by 1 practice trial, followed by 120 test trials divided in 2 blocks of 60 trials each. The amount of money and the number of days is different for each trial. Each trial lasts for 4 seconds.
SelectiveStopSignal	Similar to the Stop signal task, this task required participants to refrain from responding if a red star appears after the target stimulus is presented. In this task, however, the red star only indicates the need to inhibit the motor response in one of the two sides (critical side), while it should be ignored for the other (noncritical side). Motor response is to be given by pressing with the index finger on the corresponding button of the response box.
Stroop	In this adaptation of the classic Stroop task [Stroop, 1935](https://doi.org/10.1037/h0054651), the participants must press one of three buttons depending on the color of the presented word. In contrast to the classic pen and paper version of the task, the congruent and incongruent trials are intermixed. The three words/colors presented were red, green and blue, whose button presses corresponded on the response box respectively to the index, middle and ring fingers. The amount of money and the number of days is different for each trial.
ColumbiaCards	The Columbia card task is a gambling task in where the participants are presented with a set of cards facing down. In each trial, a different number of cards appear and the participant is informed of the amount gained per good card uncovered, the amount loss when uncovering the bad card, and the number of bad cards in the set. The participant can uncover as many cards as they want, by pressing the index finger’s button on the response box, before pressing the middle finger’s button to end the trial and start the next one. Uncovering a bad card automatically ends the trial. In each trial, the number of total cards, the number of bad cards, the amount gained per card uncovered and the amount lost if a bad card was uncovered changed. The order in which the cards is pre-determined for each trial, but the participant does not know it.
DotPatterns	This task presents the participant with pairs of stimuli, separated by a fixation cross. The participant has to press a button (index finger) as fast as possible after the presentation of the probe, and only one specific combination of cue-probe is instructed to be responded to differently. This task was designed to capture activation relative to the expectancy of the probe elicited by the correct cue.
WardAndAllport	This task is a digital version of the WATT3 task [Ward, Allport, 1997](https://doi.org/10.1080/713755681);[Shallice, 1982](https://doi.org/10.1098/rstb.1982.0082), and its main purpose is to capture activation related to planning abilities. For this, the task uses a factorial manipulation of 2 task parameters: search depth and goal hierarchy. Search depth involves mentally constructing the steps necessary to reach the goal state, and the interdependecy between steps in order to do so. This is expressed by the presence or absence of intermediate movements necessary for an optimal solution of each problem. Goal hierarchy refers to whether the order in which the three balls have to be put in their goal positions can be completely extracted from looking at the goal state or if it requires the participant to integrate information between goal and starting states (which result in unambiguous or partially ambiguous goal states, respectively). In each trial, the participant would see two configurations of the towers: the test towers on the left, and the target towers on the right. The towers of the right showed the final configuration of balls required to complete the trial. All trials could be solved in 3 movements, mani[ulated by the response button.
BiologicalMotion1	"The phenomenon known as ""biological motion"" was first introduced in [Johansson, 1973](https://doi.org/10.3758/BF03212378), and consisted in point-light displays arranged and moving in a way that resembled a person moving. The task that we used was originally developed by [Chang et al., 2018](https://doi.org/10.1016/j.neuroimage.2018.03.013). During the task, the participants are shown a point-light ""walker"", and they have to decide if the walker’s orientation is to the left or to the right, by pressing on the response box respectively on the index finger’s button or the middle finger’s button. The stimuli is divided in 6 different categories: three types of walkers, as well as their reversed versions. The division of the categories focuses on three types of information that the participant can get from the walker: global information, local information and orientation. Global information refers to the general structure of the body and the spatial relationships between its parts. Local information refers to kinematics, speed of the points and mirror-symmetric motion. Run type 1 contained both global types (natural and inverted) and both local naturals."
BiologicalMotion2	"The phenomenon known as ""biological motion"" was first introduced in [Johansson, 1973](https://doi.org/10.3758/BF03212378), and consisted in point-light displays arranged and moving in a way that resembled a person moving. The task that we used was originally developed by [Chang et al., 2018](https://doi.org/10.1016/j.neuroimage.2018.03.013). During the task, the participants are shown a point-light ""walker"", and they have to decide if the walker’s orientation is to the left or to the right, by pressing on the response box respectively on the index finger’s button or the middle finger’s button. The stimuli is divided in 6 different categories: three types of walkers, as well as their reversed versions. The division of the categories focuses on three types of information that the participant can get from the walker: global information, local information and orientation. Global information refers to the general structure of the body and the spatial relationships between its parts. Local information refers to kinematics, speed of the points and mirror-symmetric motion. Run type 2 contained both local naturals and both local modified."
Le Petit Prince	"This experiment is a natural language comprehension protocol, originally implemented by [Bhattasali et al., 2019](https://doi.org/10.1080/23273798.2018.1518533) [Hale et al.,](https://doi.org/10.1146/annurev-linguistics-051421-020803). The use of complex naturalistic language stimuli has been used to study other processes, like semantic maps [Huth et al., 2016](https://doi.org/10.1038/nature17637). Each run comprised three chapters of the ""Le Petit Prince"" story in french. During each run, the participant was presented with the audio of the story. In between runs, the experimenters would ask some multiple choice questions, as well as two or three open ended questions about the contents of the previous run, in order to keep the participants engaged. The length of the runs varied between nine and thirteen minutes. There was also a six-minutes localizer at the end of the second acquisition, in order to accurately map language areas for each participant."
MathLanguage	This protocol is a task that aims to comprehensively capture the activation related with several types of mathematical and other types of facts, presented as sentences. During the task, the participants are presented a series of sentences, each one in either of two modalities: auditory or visual. Some of the categories include theory of mind statements, arithmetic facts and geometry facts. After each sentence, the participant has to indicate whether they believe the presented fact to be true or false, by respectively pressing the button in the left or right hand.
SpatialNavigation	This protocol, an adaptation from the one used in [Diersch et al., 2021](https://doi.org/10.1523/JNEUROSCI.0528-20.2021), was originally designed to capture the effects of spatial encoding and orientation learning in different age groups. The task demands subjects to navigate and orientate themselves in a complex virtual environment. There are three parts of this task: familiarisation (outside of the scanner), encoding (in scanner) and retrieval (in scanner). Before entering the scanner, the participants would do a familiarisation phase where they would be able to freely move through the virtual environment and the objective is to collect eight red balls that can be found in different streets of the virtual city. During this time, the participants can familiarize with the different buildings and their particular features, as well as learning the location of the two key buildings that are indicated at the beginning (Town Hall and Church). After they collect all the red balls, a short training of the main task is performed to ensure the correct understanding of the instructions. The task is comprised by eight runs, from which seven of them (all except the first) starts with an encoding phase. During this period, the participant has to passively watch the camera move from one key building to the other, in such a way that every street of the virtual environment is passed through in every direction possible. Then, after the encoding phase, the retrieval phase is performed. During this part of the experiment, the task is divided in 8 experimental trials and 4 control trials per run. For every trial, the participant appears near an intersection of the virtual environment, which is now covered in a thick fog that prevents them from seeing far ahead. Then, the camera automatically approaches the intersection and stands in the center of it. The task for the participant is to point in the direction of the key building (showed in a miniature picture at the bottom of the screen). Index and middle finger’s button of the response box move respectively to the left and right whereas thumb’s button validates the answer. Control trials are identical to experimental ones, but the participant must point to one of the buildings of the intersection that has been colored in blue.
The Good, the Bad and the Ugly	The movie The Good, the Bad and the Ugly (in french Le Bon, la Brute et le Truand (BBT)) task was adapted from the study [Mantini et al., 2012](https://doi.org/10.1038/nmeth.1868), dedicated to investigate correspondence between monkey and human brains using naturalistic stimuli. The task relies on watching –viewing and listening– of the whole movie “The good, the bad and the ugly” by Sergio Leone. The original, 177-minute movie was cut into 10-minute segments (except the first two and the last ones) to adjust to the segment length of the original study, which presented only three 10-min segments of the middle of the movie. This resulted in a total of 18 segments. This task was performed during three acquisition sessions with seven segments each, one segment per run. The first three segments were repeated during the last acquisition after the movie was completed.
EmoMem	This task was designed to provide an assessment of implicit and explicit memory, and how it is affected by emotional valence. At the IBC we only conducted the encoding part of the task (the Study phase as mentioned in [Shafto et al., 2014](https://doi.org/10.1186/s12883-014-0204-1) but not the Test phase that happened outside the scanner in the original study. On each trial of this task, participants see a background picture for 2 seconds, after which a foreground picture of an object is superimposed. Participants are instructed to imagine a “story” linking the background and foreground picture, and after an 8 second presentation, the next trial begins. The emotional valence manipulation affects only the background image, which is negative, neutral, or positive.
EmoReco	This task compares brain activity when observing angry versus neutral expressions, and assesses how individuals differ in how they regulate responses to negative emotional expressions ([42]). The expressions were presented on female and male faces (15 each), and each face had an angry and a neutral expression version. On each trial, participants reported the gender of the face. Emotions were presented in blocks of angry and neutral, with equal numbers of female and male faces in each block. There were 12 blocks of each emotion and each block consisted of 5 trials. In all, 60 trials were presented per run.
StopNogo	"This task assesses systems involved in action restraint and action cancellation by randomly interleaving ""Go"", ""Stop"" and ""No-Go"" trials. On Go trials, participants viewed a black arrow pointing left or right for 1000 ms, and indicated the direction of the arrow by pressing left/right buttons with their right hand. On Stop trials, the black arrow changed colour (from black to red), after a short variable stop-signal delay. Participants were instructed that to not respond to the red arrow, so stop signal trials required cancelling the initial response to the black arrow. The Stop-Signal delay varied trial-to-trial in steps of 50 ms, and a staircase procedure was used to maintain a performance level of 66% successful inhibition. Finally, in No-Go trials, the arrow was red in colour (stop-signal delay of 0) and participants were required to make no response."
Catell / oddball	"This task was used to provide a measure of neural activity underpinning fluid intelligence Shafto et al., 2014](https://doi.org/10.1186/s12883-014-0204-1). On each trial, participants were presented with 4 images and had to identify the ""odd one out"". Some trials were easy with easily identifiable differences between the oddball and other images, while others were difficult and participants had to detect abstract patterns to identify the oddball image. The task employs a block design, where participants solve alternating blocks of easy and difficult trials, lasting 30 seconds each. In all, participants completed four blocks of easy and four blocks of difficult problems. On each trial a stimulus appears and remains on the screen until the participant responds, with the block automatically ending after 30 seconds and the next block beginning immediately. Participants were encouraged take as long as necessary, only responding when they are confident of the correct answer. This design means that the number of trials in a block varies across individuals, but the time spent on each type of problem (easy and difficult) is held constant."
FingerTapping	This task was used to study executive control and action decisions in ageing and neurodegenerative disease [Shafto et al., 2014](https://doi.org/10.1186/s12883-014-0204-1). Participants were presented with an image of a right hand and were instructed to press a button with one of their four right hand fingers in response to a cue. The cue was either a “specified” cue in which a single opaque circle indicates which finger to press, or a “chosen” cue in which 3 circles appeared opaque indicating participants must choose on of the 3 opaque fingers to press. The task includes 40 specified trials (10 for each finger) and 40 chosen trials, interspersed with 40 blank trials in which no cue is presented. Cues were presented for 1 second with a stimulus onset asynchrony of 2.5 seconds, and were pseudorandomly ordered so that participants did not see four or more responses of the same condition (action selection, specified or null) in a row.
VSTMC	On each trial, participants saw three arrays of coloured dots, one red, one yellow, and one blue. The dot displays were presented in quick succession: a 250 ms fixation was followed by a 500 ms dot display. As a manipulation of set size, one, two, or three of the dot displays moved in a single direction, which had to be remembered. The other displays rotated around a central axis, and these rotating distractor displays had be ignored. After the third display, there was an 8 s delay, during which the direction(s) of motion of non-rotating dots had to be remember. This was followed by the probe display, which had a coloured circle to indicate which dot display to recall (red, yellow, or blue). The circle contained a pointer that had to be adjusted to indicate which direction the target dot display had been moving. Participants were given 5 seconds to adjust the pointer to match the direction of the to-be-remembered dot display. On 90% of trials the probed movements were in one of three directions (7, 127, or 247 degrees).
RewProc	"This protocol was adapted from [O'Doherty J 2001](https://doi.org/10.1038/82959) and [O'Doherty J 2003](https://doi.org/10.1523/JNEUROSCI.23-21-07931.2003), which aimed at discerning the role of the orbitofrontal cortex (OFC) using a similar emotion-related visual reversal-learning task in which choice of the correct stimulus led to a probabistically determined ""monetary"" reward and choice of the incorrect stimulus led to a monetary loss.   In each trial of a run of this protocol, two unfamiliar and easily discriminable fractal patterns were displayed on a gray background, positioned to the left and right of a central fixation cross. At the beginning of the task, one of these two patterns was arbitrarily designated as ""correct"" and the other as ""incorrect"". Then, the subject's task was to to select one of these two patterns. Selection of the correct pattern led to a monetary gain with a probability of 70% and a monetary loss with a probability of 30%. On the other hand, selection of the incorrect pattern led to a monetary gain with a probability of 30% and a monetary loss with a probability of 70% (reversed gain-loss probability contingencies). On selecting either pattern, a black box appeared around it followed by a feedback on whether and how much of the symbolic money (either 20 or 10 units) was gained or lost in the particular trial. There was an equal probability whether this amount of money would be 10 or 20. Further, if the subject selected the correct pattern consecutively for a given criterion i.e. 5 times here, a reversal of the gain-loss probability contingencies occurred after a Poisson process, such that there was a probability of 25% that a reversal took place on any given post-criterion trial."
NARPS	This protocol is more commonly know as the mixed gambles task and was adapted from the Neuroimaging Analysis Replication and Prediction Study (NARPS) [Botvinik-Nezer R 2019](https://doi.org/10.1038/s41597-019-0113-7) study, that aimed to estimate the variability of neuroscientific results across analysis teams. The mixed gambles task though, is originally from [Tom SM 2007](https://doi.org/10.1126/science.1134239) that studied the neural basis of loss aversion. Loss aversion is the phenomenon that suggests that people tend to be more sensitive to losses as compared to equal-sized gains. The study therefore, investigated whether potential losses elicit negative emotions, which then drive loss aversion, or rather the same neural systems, encoding subjective value, asymmetrically respond to losses compared to gains.  In each trial of this protocol, the subjects were presented with a mixed gamble where they had a 50\% chance of either gaining one amount of symbolic money or losing another amount. The possible gains and losses both ranged between 5-20 units (equal range condition), in increments of 1 unit and all 256 possible combinations of gains and losses were presented to each subject in the same sequence. The subjects were then asked to decide whether or not they would like to accept the gambles presented to them, with four possible responses for each gamble: strongly accept, weakly accept, weakly reject or strongly reject.
FaceBody	This protocol was adapted from [Stigliani A 2015](https://doi.org/10.1523/JNEUROSCI.4822-14.2015), where it was used to define category-selective cortical regions that respond preferentially to faces (e.g., fusiform face area), places (e.g., parahippocampal place area), bodies (e.g., extrastriate body area), or printed characters (e.g., visual word form area).
Scene	"This protocol was adapted from [Douglas D 2017](https://doi.org/10.1002/hipo.22673) and was designed to identify how the brain combines spatial elements to form a coherent percept. To this end, participants judged whether Escher-like scenes were possible or impossible.  56 scenes were designed for the originaly study [Douglas D 2017](https://doi.org/10.1002/hipo.22673) that appeared spatially incoherent when viewed from a particular angle, and these were termed ""impossible scenes"". Possible counterparts were created to each impossible scene, and these were termed ""possible scenes"". For comparison, baseline non-scene images were created by scrambling the scenes and matched for low-level visual properties. A partially transparent circle was overlaid at a pseudo-random location on each of the scrambled scenes, such that half of these dots were found on the left and half on the right of the baseline scrambled images. These trials were called the ""dot trials"", and there were easy and hard versions that depended on the transparency of the overlaid circle."
BreathHolding	This task was a part of the FBIRN (Function Biomedical Informatics Research Network) [Keator DB 2016](https://doi.org/10.1016/j.neuroimage.2015.09.003) battery of protocols. It was designed to measure vascular response. In a block design, the participant alternated between breathing normally for 20 s and holding their breath for 16 s. They were given a warning 2 s before the hold breath signal was given, so they could prepare to hold their breath.
Checkerboard	This task was a part of the FBIRN (Function Biomedical Informatics Research Network) [Keator DB 2016](https://doi.org/10.1016/j.neuroimage.2015.09.003) battery of protocols. It is a block design sensorimotor task with alternating 16s long blocks of rest and visual stimulation with a checkerboard stimulus. In the checkerboard block, a checkerboard filling the visual field was presented for a period of 200 ms at random intervals (avg. ISI=762 ms, range: 500-1000 ms), and the subject pressed a button each time the checkerboard appeared on screen.
FingerTap	This task was a part of the FBIRN (Function Biomedical Informatics Research Network) [Keator DB 2016](https://doi.org/10.1016/j.neuroimage.2015.09.003) battery of protocols. It is a block design reaction time task in which subjects press one of the four keypad buttons when they see a corresponding visual cue ('1' for button1, '2' for button2 and so on).
ItemRecognition	This task was a part of the FBIRN (Function Biomedical Informatics Research Network) [Keator DB 2016](https://doi.org/10.1016/j.neuroimage.2015.09.003) battery of protocols. It is a working memory (WM) task with load 1, 3 and 5. Subjects memorize a set of targets (digits) that appear in red. They are then presented with probes (also digits) in green and respond by indicating whether the probe is a target or not. This is also a block design task with 2 blocks each with the 3 WM load conditions and 2 blocks in which subjects identify the direction of arrows on the screen (Left or Right).
VisualSearch	This protocol was adapted from [Kuo BC et al. 2016](https://www.researchgate.net/publication/297895192_Top-Down_Activation_of_Spatiotopic_Sensory_Codes_in_Perceptual_and_Working_Memory_Search), that aimed to elaborate the neurophysiological mechanism underlying the spatially specific activation of sensory codes while searching for a visual or remembered target. A set of eight stimuli items were selected from a set of 100 novel and difficult to verbalize closed shape contours previously developed by [Endo N et al. 2003](https://pubmed.ncbi.nlm.nih.gov/14708480/) in the original as well as in the IBC implementation of the study.
Color	This protocol was adapted from [McKeefry D 1997](https://doi.org/10.1093/brain/120.12.2229), that aimed at exploring the position and variability of the colour centre in the human brain.  The protocol used a mini-block design, in which 12 stimuli of the same type (either chromatic or achromatic) were presented consecutively. These stimuli were Mondrian patterns - abstract images with no recognizable objects - each composed of 20 cicular blobs of different isoluminant colors. Each run consisted of two kinds of blocks - chromatic and achromatic. During chromatic blocks, colored Mondrian patterns were presented while during achromatic blocks, grayscaled or achromatic versions of those patterns were presented. Both the conditions were equally represented in each run and the same randomized sequence of these conditions alternating with a baseline fixation cross was presented to each subject. To ensure that the subjects remained alert throughout the experiment, they were asked to press a button when an image repeated (1-back task).
Motion	This protocol was adapted from [Helfrich RF 2013](https://doi.org/10.1007/s10548-012-0226-1), that aimed at delineating areas of the visual cortex that responded to coherent visual motion under conditions of controlled attention and fixation.  In this protocol, the stimulus was composed of a rectangular random dot pattern with white dots on a dark background. Each run consisted of trials with three different conditions, namely: stationary, coherent and incoherent motion. In coherent motion condition, the motion direction was same for all dots, while in incoherent motion condition, the dots moved independently in all possible directions. For both these motion conditions, the motion direction was changed every 2 seconds in steps of 60 degrees. Due to this, the coherent motion condition was further divided into types - one where the motion direction changed clockwise and the other where it changed anti-clockwise. During the stationary condition, which was the baseline, the random dot pattern was presented with a limited dot lifetime of 1000 ms as in the motion conditions. In addition to the motion conditions, the field of presentation of the stimuli was also varied during the experiment. This means that some of the stimuli in a run were presented only on the right, others on the left hand side and the rest on the full screen.
OptimismBias	"This protocol was adapted from [Sharot T et al. 2007](https://doi.org/10.1038/nature06280.), that aimed at examining the neurobiological basis of optimism.  The subjects were presented with a series of events as text that described a life episode alongwith the word ""past"" or ""future"" to indicate that the subjects had to think of the given event such that it occurred in the past or might occur in the future. They were instructed to press a button once the memory or projection of that event was beginning to form in their mind. Following that, they had to rate the memory or projection for whether the event was (very, a little or not at all) emotionally arousing and also its valence (whether it was negative or positive)."
HarririAomic	This protocol is a part of the AOMIC battery and is published as [Snoek L 2021](https://doi.org/10.1038/s41597-021-00870-6.). It explores the processes related to (facial) emotion processing. The subjects were shown three images each trial positioned in the form of a triangle - one on the top and two on the bottom. Their task was to say that which one of the two bottom images matched with the top one and respond accordingly. During a shape condition trial, they had to match the shape of the images i.e. whether the oval shape was vertically or horizontally oriented. While during a emotion condition trial, they had to match the emotion/facial expression (either fear or anger) in the images.
FacesAomic	This protocol is a part of the AOMIC battery and is published as [Snoek L 2021](https://doi.org/10.1038/s41597-021-00870-6.). It explores the processes related to (emotional) facial perception. The stimuli here are videos of people's facial expressions, male or female, northern european or mediterranean, where they were expressing certain emotion (pride, contempt, anger, joy or no expression).
StroopAomic	"This protocol is a part of the AOMIC battery and is published as [Snoek L 2021](https://doi.org/10.1038/s41597-021-00870-6.). It protocol explores the processes related to cognitive conflict and control. The subjects were presented with images of faces of male and female models in greyscale with certain words associated with each sex in red overlayed on top of these images. The words used were French ones for ""man"", ""sir"", ""woman"", and ""lady"" in either lower or upper case. Their task was to say whether the image was that of a male or a female model while ignoring the word overlayed on top of the image."
